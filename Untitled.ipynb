{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e228ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer 'embedding' expected 1 variables, but received 0 variables during loading. Expected: ['embedding/embeddings:0']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Assume that the tokenizer and model have already been fit and trained as per previous code\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Modeli yükle\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Maksimum uzunluk ve tokenizer ayarları\u001b[39;00m\n\u001b[0;32m     13\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m964\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:254\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m         )\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    264\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:281\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    278\u001b[0m             asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:269\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m     asset_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m _load_state(\n\u001b[0;32m    270\u001b[0m     model,\n\u001b[0;32m    271\u001b[0m     weights_store\u001b[38;5;241m=\u001b[39mweights_store,\n\u001b[0;32m    272\u001b[0m     assets_store\u001b[38;5;241m=\u001b[39masset_store,\n\u001b[0;32m    273\u001b[0m     inner_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    274\u001b[0m     visited_trackables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m(),\n\u001b[0;32m    275\u001b[0m )\n\u001b[0;32m    276\u001b[0m weights_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m asset_store:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:466\u001b[0m, in \u001b[0;36m_load_state\u001b[1;34m(trackable, weights_store, assets_store, inner_path, skip_mismatch, visited_trackables)\u001b[0m\n\u001b[0;32m    457\u001b[0m     _load_state(\n\u001b[0;32m    458\u001b[0m         child_obj,\n\u001b[0;32m    459\u001b[0m         weights_store,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    463\u001b[0m         visited_trackables\u001b[38;5;241m=\u001b[39mvisited_trackables,\n\u001b[0;32m    464\u001b[0m     )\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child_obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[1;32m--> 466\u001b[0m     _load_container_state(\n\u001b[0;32m    467\u001b[0m         child_obj,\n\u001b[0;32m    468\u001b[0m         weights_store,\n\u001b[0;32m    469\u001b[0m         assets_store,\n\u001b[0;32m    470\u001b[0m         inner_path\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(inner_path, child_attr),\n\u001b[0;32m    471\u001b[0m         skip_mismatch\u001b[38;5;241m=\u001b[39mskip_mismatch,\n\u001b[0;32m    472\u001b[0m         visited_trackables\u001b[38;5;241m=\u001b[39mvisited_trackables,\n\u001b[0;32m    473\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:534\u001b[0m, in \u001b[0;36m_load_container_state\u001b[1;34m(container, weights_store, assets_store, inner_path, skip_mismatch, visited_trackables)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    533\u001b[0m     used_names[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 534\u001b[0m _load_state(\n\u001b[0;32m    535\u001b[0m     trackable,\n\u001b[0;32m    536\u001b[0m     weights_store,\n\u001b[0;32m    537\u001b[0m     assets_store,\n\u001b[0;32m    538\u001b[0m     inner_path\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(inner_path, name),\n\u001b[0;32m    539\u001b[0m     skip_mismatch\u001b[38;5;241m=\u001b[39mskip_mismatch,\n\u001b[0;32m    540\u001b[0m     visited_trackables\u001b[38;5;241m=\u001b[39mvisited_trackables,\n\u001b[0;32m    541\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:435\u001b[0m, in \u001b[0;36m_load_state\u001b[1;34m(trackable, weights_store, assets_store, inner_path, skip_mismatch, visited_trackables)\u001b[0m\n\u001b[0;32m    428\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    429\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load weights in object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrackable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m         trackable\u001b[38;5;241m.\u001b[39mload_own_variables(weights_store\u001b[38;5;241m.\u001b[39mget(inner_path))\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trackable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_assets\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m assets_store:\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_mismatch:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:3531\u001b[0m, in \u001b[0;36mLayer.load_own_variables\u001b[1;34m(self, store)\u001b[0m\n\u001b[0;32m   3529\u001b[0m all_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_weights \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_trainable_weights\n\u001b[0;32m   3530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(store\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_vars):\n\u001b[1;32m-> 3531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3532\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_vars)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m variables, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(store\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m variables during loading. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3535\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[v\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mall_vars]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3536\u001b[0m     )\n\u001b[0;32m   3537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_vars):\n\u001b[0;32m   3538\u001b[0m     \u001b[38;5;66;03m# TODO(rchao): check shapes and raise errors.\u001b[39;00m\n\u001b[0;32m   3539\u001b[0m     v\u001b[38;5;241m.\u001b[39massign(store[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: Layer 'embedding' expected 1 variables, but received 0 variables during loading. Expected: ['embedding/embeddings:0']"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "\n",
    "# Assume that the tokenizer and model have already been fit and trained as per previous code\n",
    "\n",
    "# Modeli yükle\n",
    "model = load_model('best_model.keras')\n",
    "\n",
    "# Maksimum uzunluk ve tokenizer ayarları\n",
    "max_length = 964\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "\n",
    "# Veri setini yükleyerek tokenizer'ı eğit\n",
    "def load_and_train_tokenizer(file_path):\n",
    "    import pandas as pd\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None, quotechar='\"')\n",
    "        train_urls = df[1].tolist()\n",
    "        tokenizer.fit_on_texts(train_urls)\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f'ParserError: {e}')\n",
    "\n",
    "load_and_train_tokenizer('updated_train.csv')\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    df = pd.read_csv(file_path, header=None, quotechar='\"')\n",
    "    return df\n",
    "\n",
    "# Load test dataset\n",
    "#test_df = load_dataset('dataset_phishing.csv')  # This should load your test data\n",
    "#test_df = load_dataset('phishing_site_urls.csv')  # This should load your test data\n",
    "test_df = load_dataset('combined_dataset.csv')  # This should load your test data\n",
    "\n",
    "\n",
    "# Preprocess the URLs in the test dataset\n",
    "test_urls = test_df.iloc[:, 0].tolist()  # URLs are assumed to be in the first column\n",
    "test_labels = test_df.iloc[:, -1].tolist()  # Labels are assumed to be in the last column\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "test_labels_encoded = label_encoder.fit_transform(test_labels)\n",
    "\n",
    "# Tokenize and pad the test URLs\n",
    "test_sequences = tokenizer.texts_to_sequences(test_urls)\n",
    "test_data = pad_sequences(test_sequences, maxlen=max_length)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Evaluate the predictions\n",
    "# Assuming binary classification ('legitimate' is 0 and 'phishing' is 1)\n",
    "y_pred = (predictions <= 0.5).astype(int).flatten()  # Notice the <= instead of >\n",
    "y_true = np.array(test_labels_encoded)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_true)\n",
    "print(f\"Model Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli yükle\n",
    "model = load_model(\"best_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4438f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maksimum uzunluk ve tokenizer ayarları\n",
    "max_length = 964\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "\n",
    "# Veri setini yükleyerek tokenizer'ı eğit\n",
    "def load_and_train_tokenizer(file_path):\n",
    "    import pandas as pd\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None, quotechar='\"')\n",
    "        train_urls = df[1].tolist()\n",
    "        tokenizer.fit_on_texts(train_urls)\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f'ParserError: {e}')\n",
    "\n",
    "load_and_train_tokenizer('updated_train.csv')\n",
    "\n",
    "# Load test dataset\n",
    "#test_df = load_dataset('dataset_phishing.csv')  # This should load your test data\n",
    "#test_df = load_dataset('phishing_site_urls.csv')  # This should load your test data\n",
    "test_df = load_dataset('combined_dataset.csv')  # This should load your test data\n",
    "\n",
    "\n",
    "# Preprocess the URLs in the test dataset\n",
    "test_urls = test_df.iloc[:, 0].tolist()  # URLs are assumed to be in the first column\n",
    "test_labels = test_df.iloc[:, -1].tolist()  # Labels are assumed to be in the last column\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "test_labels_encoded = label_encoder.fit_transform(test_labels)\n",
    "\n",
    "# Tokenize and pad the test URLs\n",
    "test_sequences = tokenizer.texts_to_sequences(test_urls)\n",
    "test_data = pad_sequences(test_sequences, maxlen=max_length)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Evaluate the predictions\n",
    "# Assuming binary classification ('legitimate' is 0 and 'phishing' is 1)\n",
    "y_pred = (predictions <= 0.5).astype(int).flatten()  # Notice the <= instead of >\n",
    "y_true = np.array(test_labels_encoded)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_true)\n",
    "print(f\"Model Accuracy: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
